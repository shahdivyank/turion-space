{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120a7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a753090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load original CSV and parse items ---\n",
    "df = pd.read_csv(\"thermal_data.csv\")\n",
    "df['parsed_items'] = df['items'].apply(json.loads)\n",
    "sensor_df = pd.DataFrame(df['parsed_items'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e607f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Interpolate sensors to 1000 rows ---\n",
    "sensor_df.index = pd.Index(range(len(sensor_df)))\n",
    "new_index = pd.Index(np.linspace(0, len(sensor_df) - 1, 1000))\n",
    "sensor_df_1000 = sensor_df.reindex(new_index).interpolate(method='linear').round(2)\n",
    "sensor_df_1000 = sensor_df_1000.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7901d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate std deviation per sensor (column-wise) from the original data\n",
    "std_per_sensor = sensor_df.std()\n",
    "# Inject small Gaussian noise scaled to each sensor\n",
    "noise = np.random.normal(loc=0, scale=std_per_sensor/25, size=sensor_df_1000.shape)\n",
    "sensor_df_1000_noisy = (sensor_df_1000 + noise).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ede9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 1%–2% of rows to insert anomalies into (e.g., 10–20 points)\n",
    "num_anomalies = 50\n",
    "anomaly_rows = random.sample(range(len(sensor_df_1000_noisy)), num_anomalies)\n",
    "\n",
    "for row in anomaly_rows:\n",
    "    # Generate one random spike value per sensor (20–62°C)\n",
    "    spike_values = np.random.uniform(20, 62, size=sensor_df_1000_noisy.shape[1])\n",
    "    \n",
    "    # Inject all values at once into the row\n",
    "    sensor_df_1000_noisy.iloc[row] = np.round(spike_values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edab1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[329,\n",
       " 371,\n",
       " 970,\n",
       " 823,\n",
       " 189,\n",
       " 136,\n",
       " 372,\n",
       " 545,\n",
       " 663,\n",
       " 466,\n",
       " 338,\n",
       " 183,\n",
       " 392,\n",
       " 616,\n",
       " 134,\n",
       " 486,\n",
       " 910,\n",
       " 697,\n",
       " 103,\n",
       " 728,\n",
       " 262,\n",
       " 245,\n",
       " 759,\n",
       " 331,\n",
       " 496,\n",
       " 480,\n",
       " 928,\n",
       " 235,\n",
       " 859,\n",
       " 390,\n",
       " 695,\n",
       " 82,\n",
       " 843,\n",
       " 963,\n",
       " 206,\n",
       " 867,\n",
       " 401,\n",
       " 866,\n",
       " 683,\n",
       " 802,\n",
       " 829,\n",
       " 565,\n",
       " 658,\n",
       " 636,\n",
       " 446,\n",
       " 258,\n",
       " 544,\n",
       " 101,\n",
       " 35,\n",
       " 459]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b5f76b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Create 1000 timestamps in descending order ---\n",
    "df['packet_time'] = pd.to_datetime(df['packet_time'])\n",
    "start_time = df['packet_time'].iloc[0]  # latest time\n",
    "end_time = df['packet_time'].iloc[-1]   # oldest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2a3ff6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 evenly spaced times between start and end\n",
    "packet_times = pd.date_range(start=start_time, end=end_time, periods=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "21fbf70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Rebuild final DataFrame ---\n",
    "df_expanded = pd.DataFrame({\n",
    "    'packet_time': packet_times,\n",
    "    'items': sensor_df_1000_noisy.apply(lambda row: json.dumps(row.to_dict()), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "799f5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded['boot_count'] = 6450\n",
    "df_expanded['spacecraft'] = \"DEFAULT\"\n",
    "df_expanded['target'] = \"THERMAL\"\n",
    "df_expanded['packet'] = \"THERMAL_HK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d6d77df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.to_csv('1000_thermal_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
